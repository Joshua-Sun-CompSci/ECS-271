{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38cc98af",
   "metadata": {},
   "source": [
    "### Generation configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb2935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# === Config ===\n",
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "checkpoint_path = \"output/checkpoint-42600\"\n",
    "\n",
    "# === Tokenizer ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# === QLoRA quantization config ===\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "# === Load model from fine-tuned checkpoint ===\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    checkpoint_path,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b230e7bd",
   "metadata": {},
   "source": [
    "### Prompt + generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b11e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Write an academic paragraph given the title.\n",
      "\n",
      "### Input:\n",
      "SnapMix\n",
      "\n",
      "### Response:\n",
      "This paper presents SnapMix, a new method to generate images from a text prompt. It leverages diffusion models by generating multiple images that are later combined. This approach allows for a more controlled and flexible image generation process compared to conventional diffusion models. The method is evaluated on the LLAMA-7B model, demonstrating improvements in image quality and diversity. Additionally, the paper introduces a new dataset, SnapMix-1M, which consists of 1 million text-image pairs generated by SnapMix. This dataset is designed to support further research and development in image generation. The code and dataset will be made publicly available. The code and dataset will be made publicly available at https://github.com/sakuraz\n"
     ]
    }
   ],
   "source": [
    "# === Change the Input to generate\n",
    "prompt = \"\"\"### Instruction:\n",
    "Write an academic paragraph given the title.\n",
    "\n",
    "### Input: \n",
    "SnapMix\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "# === Tokenize and generate ===\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=150,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "# === Decode ===\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
